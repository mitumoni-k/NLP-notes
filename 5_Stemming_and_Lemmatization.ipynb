{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccd43fea",
   "metadata": {},
   "source": [
    "## Stemming \n",
    "      -> use of fixed rules to derive a base word is basicaaly stemming\n",
    "      -> SpaCy doesn't have any support for Stemming, hence we'll be using             NLTK., as they already have lemmatization integrated in their library...But NLTK supports both Stemming and Lemmatization.\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4daeaa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5378b3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer # PorterStemmer is a class\n",
    "\n",
    "stemmer = PorterStemmer()   # creating an object of that class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f20731c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating  |  eat\n",
      "eats  |  eat\n",
      "eat  |  eat\n",
      "ate  |  ate\n",
      "adjustable  |  adjust\n",
      "rafting  |  raft\n",
      "ability  |  abil\n",
      "meeting  |  meet\n"
     ]
    }
   ],
   "source": [
    "words = [\"eating\",\"eats\",\"eat\",\"ate\",\"adjustable\",\"rafting\",\"ability\",\"meeting\"]\n",
    "\n",
    "for word in words:\n",
    "    print(word , \" | \", stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69020db",
   "metadata": {},
   "source": [
    "## Lemmatization\n",
    "    -> using the knowledge of a language (a.k.a linguistic knowledge) to derive a base word(lemma) is basically lemmatization \n",
    "    -> we'll be using SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f585167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   |   \n",
      "eating  |  eat\n",
      "eats  |  eat\n",
      "eat  |  eat\n",
      "ate  |  eat\n",
      "adjustable  |  adjustable\n",
      "rafting  |  raft\n",
      "ability  |  ability\n",
      "meeting  |  meeting\n",
      "better  |  well\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc = nlp(\" eating eats eat ate adjustable rafting ability meeting better\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token , \" | \", token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1fe9834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mando  |  Mando\n",
      "talked  |  talk\n",
      "for  |  for\n",
      "3  |  3\n",
      "hours  |  hour\n",
      "although  |  although\n",
      "talking  |  talk\n",
      "is  |  be\n",
      "n't  |  not\n",
      "his  |  his\n",
      "thing  |  thing\n",
      "and  |  and\n",
      "he  |  he\n",
      "became  |  become\n",
      "talkative  |  talkative\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Mando talked for 3 hours although talking isn't his thing and he became talkative\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token , \" | \", token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "486fa174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9db8765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attribute_ruler assigns attribute to the particular token\n",
    "# tagger is used for determining the Part Of Speech(POS)\n",
    "# lemmatizer is used for generating the base words.\n",
    "\n",
    "# add_pipe() ->  adds a particular component to the pipeline\n",
    "# get_pipe() -> gets a particular component from the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4e7857",
   "metadata": {},
   "source": [
    "### Customizing Attribute Ruler component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a90b47be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bro  |  bro\n",
      ",  |  ,\n",
      "   |   \n",
      "you  |  you\n",
      "wanna  |  wanna\n",
      "go  |  go\n",
      "?  |  ?\n",
      "Brah  |  Brah\n",
      ",  |  ,\n",
      "do  |  do\n",
      "n't  |  not\n",
      "say  |  say\n",
      "no  |  no\n",
      "!  |  !\n",
      "I  |  I\n",
      "am  |  be\n",
      "Exhausted  |  exhaust\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Bro ,  you wanna go ? Brah, don't say no! I am Exhausted\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token , \" | \", token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6c07fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bro  |  Brother\n",
      ",  |  ,\n",
      "   |   \n",
      "you  |  you\n",
      "wanna  |  wanna\n",
      "go  |  go\n",
      "?  |  ?\n",
      "Brah  |  Brother\n",
      ",  |  ,\n",
      "do  |  do\n",
      "n't  |  not\n",
      "say  |  say\n",
      "no  |  no\n",
      "!  |  !\n",
      "I  |  I\n",
      "am  |  be\n",
      "Exhausted  |  exhaust\n"
     ]
    }
   ],
   "source": [
    "## customizing the attribute rules\n",
    "atr = nlp.get_pipe('attribute_ruler')\n",
    "atr.add([[{\"TEXT\" : \"Bro\"}] , [{\"TEXT\" : \"Brah\"}]], {\"LEMMA\" : \"Brother\"}) # change the base word of 'Bro' and 'Brah' to 'Brother'\n",
    "\n",
    "\n",
    "doc = nlp(\"Bro ,  you wanna go ? Brah, don't say no! I am Exhausted\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token , \" | \", token.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedab1d3",
   "metadata": {},
   "source": [
    "## Exercises :\n",
    "\n",
    "Q1. Convert these list of words into base form using Stemming and Lemmatization and observe the transformations.\n",
    "  \n",
    "\n",
    "Q2. convert the given text into it's base form using both stemming and lemmatization\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25cdaa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7773468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running  |  run\n",
      "painting  |  paint\n",
      "walking  |  walk\n",
      "dressing  |  dress\n",
      "likely  |  like\n",
      "children  |  children\n",
      "whom  |  whom\n",
      "good  |  good\n",
      "ate  |  ate\n",
      "fishing  |  fish\n"
     ]
    }
   ],
   "source": [
    "# performing stemming - Solution 1\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "lst_words = ['running', 'painting', 'walking', 'dressing', 'likely', 'children', 'whom', 'good', 'ate', 'fishing']\n",
    "\n",
    "for word in lst_words:\n",
    "    print(word , \" | \", stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5ebaa42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running  |  run\n",
      "painting  |  paint\n",
      "walking  |  walk\n",
      "dressing  |  dress\n",
      "likely  |  likely\n",
      "children  |  child\n",
      "who  |  who\n",
      "good  |  good\n",
      "ate  |  eat\n",
      "fishing  |  fishing\n"
     ]
    }
   ],
   "source": [
    "# performing lemmatization - Solution 1\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc = nlp(\"running painting walking dressing likely children who good ate fishing\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token, \" | \",token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7b67365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latha is veri multi talent girl.sh is good at mani skill like danc , run , sing , playing.sh also like eat pav bhagi . she ha a habit of fish and swim too.besid all thi , she is a wonder at cook too .\n"
     ]
    }
   ],
   "source": [
    "# using stemming for solution - 2\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "text = \"\"\"Latha is very multi talented girl.She is good at many skills like dancing, running, singing, playing.She also likes eating Pav Bhagi. she has a \n",
    "habit of fishing and swimming too.Besides all this, she is a wonderful at cooking too.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# step1 : word tokenizing    \n",
    "word_tokens = nltk.word_tokenize(text)\n",
    "\n",
    "# step2 : getting the base form for each token using stemmer\n",
    "base_words = []\n",
    "\n",
    "for token in word_tokens:\n",
    "    base_form = stemmer.stem(token)\n",
    "    base_words.append(base_form) \n",
    "\n",
    "# step3 : joining all the words in a list into string using 'join' \n",
    "final_text = ' '.join(base_words)\n",
    "print(final_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dfff4745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latha be very multi talented girl . she be good at many skill like dancing , running , singing , play . she also like eat Pav Bhagi . she have a \n",
      " habit of fishing and swim too . besides all this , she be a wonderful at cook too . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# using lemmatization in SpaCy for solution - 2\n",
    "\n",
    "text = \"\"\"Latha is very multi talented girl.She is good at many skills like dancing, running, singing, playing.She also likes eating Pav Bhagi. she has a \n",
    "habit of fishing and swimming too.Besides all this, she is a wonderful at cooking too.\n",
    "\"\"\"\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "#step1: Creating the object for the given text\n",
    "doc = nlp(text)\n",
    "base_words = []\n",
    "\n",
    "#step2: getting the base form for each token using spacy 'lemma_'\n",
    "for token in doc:\n",
    "    base_words.append(token.lemma_)\n",
    "    \n",
    "#step3: joining all words in a list into string using 'join()'\n",
    "final_text = \" \".join(base_words)\n",
    "print(final_text)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bc47bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3421c847",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
